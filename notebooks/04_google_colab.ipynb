{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce9d5d1",
   "metadata": {},
   "source": [
    "# Colab Edition\n",
    "\n",
    "**What this is**  \n",
    "A Google Colabâ€“oriented notebook that **combines Notebook 02 (Pre-processing)** and **Notebook 03 (Model Training & Evaluation)** into one place. Only **minor changes** were made to make it Colab-friendly.\n",
    "\n",
    "**What changed (lightly):**\n",
    "- Path handling that works on Colab (optional Google Drive mount + safe `DATA_DIR/RESULTS_DIR` defaults).\n",
    "- Silent install of `python-chess` if missing.\n",
    "- Small housekeeping for deterministic seeds and progress printing.\n",
    "- No logic changes to the core pipeline or model.\n",
    "\n",
    "**How to use (Colab):**\n",
    "1. *(Optional)* Mount Google Drive and set `DATA_DIR` to your project folder.  \n",
    "2. Run the cells **top-to-bottom**:\n",
    "   - **A. Pre-processing**: load raw CSV â†’ tokenize SAN â†’ keep first 60 plies â†’ add light features (captures/checks [+ optional Elo]) â†’ save clean CSV & meta.\n",
    "   - **B. Training & Evaluation**: build splits & vocab â†’ create `tf.data` â†’ train BiGRU model â†’ tune threshold on **val** â†’ evaluate on **test**.\n",
    "3. Outputs are written to `results/`.\n",
    "\n",
    "**Expected inputs**\n",
    "- `data/chess_games_subset.csv` (moves in SAN/AN + result).  \n",
    "  You can point `DATA_DIR` to a different location if needed.\n",
    "\n",
    "**Saved artifacts (in `results/`):**\n",
    "- `best_seq_model.keras`, `seq_report.json`, `label_mapping.json`, `class_weights.json` *(if used)*, `vocab.json`, `dl_config.json`.\n",
    "\n",
    "> Tip: If running from Drive, keep your folder layout as in the repo (`data/`, `results/`) to avoid path edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5746a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Colab setup: mount Drive + robust project paths ===\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "# 1) Mount Google Drive if running on Colab\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "# 2) Point to your project folder name in Drive\n",
    "REPO_NAME = \"chess-outcome-prediction\"  # <-- change if your folder name differs\n",
    "\n",
    "def find_project_root():\n",
    "    \"\"\"Find the project root that contains 'data' and 'notebooks'.\"\"\"\n",
    "    # Common places in Drive\n",
    "    candidates = [\n",
    "        Path(\"/content/drive/MyDrive\") / REPO_NAME,\n",
    "        Path(\"/content/drive/MyDrive/Colab Notebooks\") / REPO_NAME,\n",
    "        Path.cwd(),  # in case notebook is opened inside the repo already\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if (p / \"data\").exists() and (p / \"notebooks\").exists():\n",
    "            return p.resolve()\n",
    "\n",
    "    # Walk up from current dir as a fallback\n",
    "    here = Path.cwd().resolve()\n",
    "    for parent in [here, *here.parents]:\n",
    "        if (parent / \"data\").exists() and (parent / \"notebooks\").exists():\n",
    "            return parent.resolve()\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate the project root. \"\n",
    "        \"Set REPO_NAME correctly or move this notebook inside the repo.\"\n",
    "    )\n",
    "\n",
    "PROJ_DIR = find_project_root()\n",
    "\n",
    "# 3) Define standard paths (used by your notebooks)\n",
    "NB_DIR      = Path.cwd()\n",
    "DATA_DIR    = PROJ_DIR / \"data\"\n",
    "RESULTS_DIR = PROJ_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4) File paths used across notebooks\n",
    "RAW_SUBSET  = DATA_DIR / \"chess_games_subset.csv\"\n",
    "CLEAN_CSV   = DATA_DIR / \"chess_games_clean.csv\"\n",
    "META_JSON   = DATA_DIR / \"chess_games_clean_meta.json\"\n",
    "BOARDS_NPZ  = DATA_DIR / \"chess_boards_8x8xC.npz\"\n",
    "\n",
    "print(\"Project dir :\", PROJ_DIR)\n",
    "print(\"Data dir    :\", DATA_DIR)\n",
    "print(\"Results dir :\", RESULTS_DIR)\n",
    "print(\"RAW_SUBSET exists? \", RAW_SUBSET.exists())\n",
    "\n",
    "# Optional: fail early with a clear message if files are missing\n",
    "assert RAW_SUBSET.exists(), (\n",
    "    f\"Missing {RAW_SUBSET}. Place your CSVs in: {DATA_DIR}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ðŸ”§ Colab GPU setup (run once, before training)\n",
    "# This cell configures TensorFlow to use the Colab GPU efficiently.\n",
    "# If no GPU is found, you'll see a hint to enable it in Runtime â†’ Change runtime type â†’ GPU.\n",
    "\n",
    "import os, tensorflow as tf\n",
    "\n",
    "# Optional toggles (editable in Colab UI)\n",
    "USE_MIXED_PRECISION = True  # @param {type:\"boolean\"}\n",
    "USE_XLA             = True  # @param {type:\"boolean\"}\n",
    "LIMIT_GPU_MEM_GROWTH = True # @param {type:\"boolean\"}\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "\n",
    "# 1) Detect GPU\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if not gpus:\n",
    "    print(\n",
    "        \"âš ï¸  No GPU detected. In Colab: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU, then rerun.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"âœ… GPU(s) found: {[g.name for g in gpus]}\")\n",
    "\n",
    "    # 2) Safer memory handling\n",
    "    if LIMIT_GPU_MEM_GROWTH:\n",
    "        try:\n",
    "            for g in gpus:\n",
    "                tf.config.experimental.set_memory_growth(g, True)\n",
    "            print(\"ðŸ§  Enabled memory growth on GPU(s).\")\n",
    "        except Exception as e:\n",
    "            print(\"Memory growth setup warning:\", e)\n",
    "\n",
    "    # 3) Optional speed-ups\n",
    "    if USE_XLA:\n",
    "        try:\n",
    "            tf.config.optimizer.set_jit(True)  # enable XLA\n",
    "            print(\"âš¡ Enabled XLA (JIT compilation).\")\n",
    "        except Exception as e:\n",
    "            print(\"XLA setup warning:\", e)\n",
    "\n",
    "    # Enable TF32 on Ampere+ (speeds up matmul/conv with tiny precision tradeoff)\n",
    "    try:\n",
    "        tf.config.experimental.enable_tensor_float_32_execution(True)\n",
    "        print(\"ðŸ”¢ Enabled TF32 execution where supported.\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    # 4) Mixed precision (recommended on recent GPUs)\n",
    "    if USE_MIXED_PRECISION:\n",
    "        try:\n",
    "            from tensorflow.keras import mixed_precision\n",
    "            mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "            # Tip: keep the final output layer in float32 or rely on Keras automatic casting.\n",
    "            print(f\"ðŸ§ª Mixed precision policy: {mixed_precision.global_policy()}\")\n",
    "        except Exception as e:\n",
    "            print(\"Mixed precision setup warning:\", e)\n",
    "\n",
    "    # 5) Show the logical devices weâ€™ll use\n",
    "    print(\"Devices in use:\", tf.config.list_logical_devices())\n",
    "\n",
    "print(\"GPU setup complete. Proceed to training âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf3948",
   "metadata": {},
   "source": [
    "# CHESS OUTCOME PREDICTION â€” PRE-PROCESSING\n",
    "\n",
    "**Goal**: build a clean sequence-only dataset (plus optional 8Ã—8Ã—C board tensors) for model training.  \n",
    "**Cut-off**: first **30 full moves** (60 plies).\n",
    "\n",
    "**I/O**\n",
    "- **Input**: `data/chess_games_subset.csv` (SAN/AN moves, `Result`, Elo, etc.)\n",
    "- **Outputs**:\n",
    "  - `data/chess_games_clean.csv`\n",
    "  - `data/chess_games_clean_meta.json`\n",
    "  - *(optional)* `data/chess_boards_8x8xC.npz` (board planes)\n",
    "\n",
    "**Pipeline (overview)**\n",
    "1. Load subset -> normalize labels to `{white, black, draw}`.\n",
    "2. Tokenize SAN/AN; strip move numbers/results -> keep first **60 plies**.\n",
    "3. Add features: `plies_processed`, `cutoff_reached`, `captures_in_first_30_moves`, `checks_in_first_30_moves`.\n",
    "4. Elo features: compute `elo_diff = white_elo - black_elo`, `elo_avg`.\n",
    "5. Leakage guard: drop raw winner/result/Elo columns from features.\n",
    "6. Impute & downcast numerics.\n",
    "7. *(Optional)* Export 8Ã—8Ã—C board planes at plies `[20, 40, 60]`.\n",
    "8. Sanity checks (class balance, NAs, sequence length) -> save CSV & meta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python-chess OK.\n",
      "Data dir: E:\\Github Projects\\chess-outcome-prediction\\data\n",
      "Input : E:\\Github Projects\\chess-outcome-prediction\\data\\chess_games_subset.csv\n",
      "Output: E:\\Github Projects\\chess-outcome-prediction\\data\\chess_games_clean.csv\n",
      "Cutoff: 30 moves (60 plies)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1. Imports & Paths\n",
    "# ==============================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.1 Ensure python-chess\n",
    "# ----------------------------------------------\n",
    "try:\n",
    "    import chess\n",
    "except ModuleNotFoundError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-chess\", \"--quiet\"])\n",
    "    import chess\n",
    "print(\"python-chess OK.\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.2 Config (sequence only)\n",
    "# ----------------------------------------------\n",
    "CUTOFF_FULL_MOVES = 30\n",
    "CUTOFF_PLIES = CUTOFF_FULL_MOVES * 2\n",
    "MOVE_COL = f\"moves_first{CUTOFF_FULL_MOVES}_san\"\n",
    "CAPTURES_COL = f\"captures_in_first_{CUTOFF_FULL_MOVES}_moves\"\n",
    "CHECKS_COL = f\"checks_in_first_{CUTOFF_FULL_MOVES}_moves\"\n",
    "SEQUENCE_ONLY = True\n",
    "INCLUDE_ELO   = True\n",
    "\n",
    "CHECKPOINT_PLIES = [20, 40, 60]         \n",
    "BOARDS_NPZ = DATA_DIR / \"chess_boards_8x8xC.npz\"\n",
    "\n",
    "print(\"Data dir:\", DATA_DIR)\n",
    "print(\"Input :\", RAW_SUBSET)\n",
    "print(\"Output:\", CLEAN_CSV)\n",
    "print(f\"Cutoff: {CUTOFF_FULL_MOVES} moves ({CUTOFF_PLIES} plies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a3faea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(449359, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_raw</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. f4 d5 2. g3 c5 3. Bg2 Nc6 4. Nf3 Bf5 5. O-O...</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. e4 b6 2. d4 Bb7 3. Bd3 e6 4. f4 d6 5. Nf3 h...</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. d4 Nf6 2. c4 e6 3. Nc3 c5 4. d5 d6 5. e3 e5...</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           moves_raw target\n",
       "0  1. f4 d5 2. g3 c5 3. Bg2 Nc6 4. Nf3 Bf5 5. O-O...  white\n",
       "1  1. e4 b6 2. d4 Bb7 3. Bd3 e6 4. f4 d6 5. Nf3 h...  white\n",
       "2  1. d4 Nf6 2. c4 e6 3. Nc3 c5 4. d5 d6 5. e3 e5...  black"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Load Subset\n",
    "# ==============================================\n",
    "df_raw = pd.read_csv(RAW_SUBSET)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.1 Detect Columns\n",
    "# ----------------------------------------------\n",
    "cols = {c.lower(): c for c in df_raw.columns}\n",
    "\n",
    "an_col = None\n",
    "for k in [\"an\", \"moves\", \"algebraic\", \"algebraicnotation\"]:\n",
    "    if k in cols:\n",
    "        an_col = cols[k]\n",
    "        break\n",
    "if an_col is None:\n",
    "    raise ValueError(\"Moves column (AN) not found. Expected a column like 'AN' or 'Moves'.\")\n",
    "\n",
    "label_col = None\n",
    "for k in [\"result\", \"target\", \"winner\", \"outcome\"]:\n",
    "    if k in cols:\n",
    "        label_col = cols[k]\n",
    "        break\n",
    "if label_col is None:\n",
    "    raise ValueError(\"Label column not found. Expected 'Result' or similar.\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.2 Clean Labels\n",
    "# ----------------------------------------------\n",
    "def map_label(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if s in {\"1-0\", \"white\", \"w\"}:\n",
    "        return \"white\"\n",
    "    if s in {\"0-1\", \"black\", \"b\"}:\n",
    "        return \"black\"\n",
    "    if s in {\"1/2-1/2\", \"draw\", \"d\"}:\n",
    "        return \"draw\"\n",
    "    return np.nan\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"moves_raw\": df_raw[an_col].astype(str),\n",
    "        \"target\": df_raw[label_col].map(map_label),\n",
    "    }\n",
    ").dropna(subset=[\"moves_raw\", \"target\"]).reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a23c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(449359, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_first30_san</th>\n",
       "      <th>plies_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f4 d5 g3 c5 Bg2 Nc6 Nf3 Bf5 O-O e6 d3 g6 Be3 h...</td>\n",
       "      <td>33</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e4 b6 d4 Bb7 Bd3 e6 f4 d6 Nf3 h6 O-O a6 Qe2 Ne...</td>\n",
       "      <td>28</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   moves_first30_san  plies_processed target\n",
       "0  f4 d5 g3 c5 Bg2 Nc6 Nf3 Bf5 O-O e6 d3 g6 Be3 h...               33  white\n",
       "1  e4 b6 d4 Bb7 Bd3 e6 f4 d6 Nf3 h6 O-O a6 Qe2 Ne...               28  white\n",
       "2  d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...               60  black"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 3. Extract First 30 Moves (60 plies)\n",
    "# ==============================================\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 3.1 Helpers\n",
    "# ----------------------------------------------\n",
    "RESULT_TOKENS = {\"1-0\", \"0-1\", \"1/2-1/2\"}\n",
    "\n",
    "def tokenize_an(s: str):\n",
    "    toks = str(s).replace(\"\\r\", \" \").replace(\"\\n\", \" \").split()\n",
    "    keep = []\n",
    "    for t in toks:\n",
    "        if t.endswith(\".\") and t[:-1].isdigit():\n",
    "            continue\n",
    "        if t == \"...\":\n",
    "            continue\n",
    "        if t in RESULT_TOKENS:\n",
    "            continue\n",
    "        keep.append(t)\n",
    "    return keep\n",
    "\n",
    "def count_captures(seq): \n",
    "    return sum(\"x\" in m for m in seq)\n",
    "\n",
    "def count_checks(seq): \n",
    "    return sum((\"+\" in m) or (\"#\" in m) for m in seq)\n",
    "\n",
    "# --- Board helpers (append) ---\n",
    "def _board_planes(b):\n",
    "    # 12 planes: white/black {P,N,B,R,Q,K} -> (8,8,12) uint8\n",
    "    planes = []\n",
    "    for color, pieces in [(chess.WHITE, [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]),\n",
    "                          (chess.BLACK, [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING])]:\n",
    "        for p in pieces:\n",
    "            plane = np.zeros((8, 8), dtype=np.uint8)\n",
    "            for sq in b.pieces(p, color):\n",
    "                r = 7 - (sq // 8); c = sq % 8\n",
    "                plane[r, c] = 1\n",
    "            planes.append(plane)\n",
    "    return np.stack(planes, axis=-1)  # (8,8,12)\n",
    "\n",
    "def boards_from_san_list(san_list, checkpoints=CHECKPOINT_PLIES):\n",
    "    b = chess.Board()\n",
    "    out = []\n",
    "    want = list(checkpoints)\n",
    "    ply = 0\n",
    "    for m in san_list:\n",
    "        try:\n",
    "            b.push_san(m)\n",
    "        except Exception:\n",
    "            break\n",
    "        ply += 1\n",
    "        while want and ply >= want[0]:\n",
    "            out.append(_board_planes(b))\n",
    "            want.pop(0)\n",
    "    while want:  # pad with empty boards if short\n",
    "        out.append(np.zeros((8, 8, 12), dtype=np.uint8))\n",
    "        want.pop(0)\n",
    "    return np.concatenate(out, axis=-1)  # (8,8, 12*len(checkpoints))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 3.2 Build Sequence Columns\n",
    "# ----------------------------------------------\n",
    "tokens = df[\"moves_raw\"].apply(tokenize_an)\n",
    "tokens_cut = tokens.apply(lambda t: t[:CUTOFF_PLIES])\n",
    "\n",
    "df[MOVE_COL] = tokens_cut.apply(lambda t: \" \".join(t))\n",
    "df[\"plies_processed\"] = tokens_cut.apply(len)\n",
    "df[\"cutoff_reached\"] = (df[\"plies_processed\"] == CUTOFF_PLIES).astype(int)\n",
    "df[CAPTURES_COL] = tokens_cut.apply(count_captures)\n",
    "df[CHECKS_COL] = tokens_cut.apply(count_checks)\n",
    "\n",
    "df = df.dropna(subset=[MOVE_COL, \"target\"]).reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df[[MOVE_COL, \"plies_processed\", \"target\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b2c1f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elo detected â†’ White: 'WhiteElo', Black: 'BlackElo'. Added white_elo/black_elo + elo_diff/elo_avg.\n",
      "Kept games reaching 60 plies: 281021/449359 (62.5%)\n",
      "Kept non-draws: 265022/281021 (94.3%)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 4. Assemble Working Frame (sequence-only, no leakage)\n",
    "# ==============================================\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.1 Select Columns\n",
    "# ----------------------------------------------\n",
    "keep_cols = [MOVE_COL, \"plies_processed\", \"cutoff_reached\", CAPTURES_COL, CHECKS_COL, \"target\"]\n",
    "missing = [c for c in keep_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns: {missing}\")\n",
    "\n",
    "X = df[keep_cols].copy()\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.2 Leakage Guard\n",
    "# ----------------------------------------------\n",
    "banned = {\n",
    "    \"Result\",\"result\",\"winner\",\"Winner\",\"termination\",\"Termination\",\n",
    "    \"num_moves\",\"NumMoves\",\"Opening\",\"opening\",\"ECO\",\"eco\",\"Moves\",\"AN\",\n",
    "    \"UTCDate\",\"UTCTime\",\"Event\",\"TimeControl\",\"White\",\"Black\",\n",
    "    \"WhiteElo\",\"BlackElo\",\"white_elo\",\"black_elo\",\n",
    "    \"WhiteRating\",\"BlackRating\",\"WhiteRatingDiff\",\"BlackRatingDiff\"\n",
    "}\n",
    "present_banned = [c for c in X.columns if c in banned]\n",
    "assert not present_banned, f\"Leaky columns present in X: {present_banned}\"\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.3 Types\n",
    "# ----------------------------------------------\n",
    "X[MOVE_COL] = X[MOVE_COL].fillna(\"\").astype(str)\n",
    "X[\"target\"] = X[\"target\"].astype(str)\n",
    "for c in [\"plies_processed\", \"cutoff_reached\", CAPTURES_COL, CHECKS_COL]:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.4 Elo Features (pre-game, derived only; read from df_raw)\n",
    "# ----------------------------------------------\n",
    "# robust selection (case-insensitive; supports Elo or Rating; ignores *Diff)\n",
    "lower_map = {c.lower(): c for c in df_raw.columns}\n",
    "\n",
    "def pick_rating(side: str):\n",
    "    side_l = side.lower()\n",
    "    prefs = [\n",
    "        f\"{side_l}elo\", f\"{side_l}_elo\",\n",
    "        f\"{side_l}rating\", f\"{side_l}_rating\",\n",
    "    ]\n",
    "    for p in prefs:\n",
    "        if p in lower_map:\n",
    "            return lower_map[p]\n",
    "    cands = [c for c in df_raw.columns\n",
    "             if (side_l in c.lower()) and ((\"elo\" in c.lower()) or (\"rating\" in c.lower()))]\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "w_col = pick_rating(\"White\")\n",
    "b_col = pick_rating(\"Black\")\n",
    "\n",
    "if w_col and b_col:\n",
    "    # Explicit, side-aware columns kept in the CLEAN set\n",
    "    X[\"white_elo\"] = pd.to_numeric(df_raw[w_col], errors=\"coerce\")\n",
    "    X[\"black_elo\"] = pd.to_numeric(df_raw[b_col], errors=\"coerce\")\n",
    "\n",
    "    # Directional diff (white - black) and average derived from the above\n",
    "    X[\"elo_diff\"] = (X[\"white_elo\"] - X[\"black_elo\"])\n",
    "    X[\"elo_avg\"]  = (X[\"white_elo\"] + X[\"black_elo\"]) / 2.0\n",
    "\n",
    "    # Coerce types (plays nicely with your Section 5 downcast)\n",
    "    X[\"elo_diff\"] = pd.to_numeric(X[\"elo_diff\"], errors=\"coerce\")\n",
    "    X[\"elo_avg\"]  = pd.to_numeric(X[\"elo_avg\"],  errors=\"coerce\")\n",
    "\n",
    "    print(f\"Elo detected â†’ White: '{w_col}', Black: '{b_col}'. \"\n",
    "          f\"Added white_elo/black_elo + elo_diff/elo_avg.\")\n",
    "else:\n",
    "    print(\"No Elo columns detected in df_raw; skipping Elo features.\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.5 Filter: require the game to reach the cutoff\n",
    "# ----------------------------------------------\n",
    "REQUIRE_CUTOFF = True  # set False if you want to keep everything\n",
    "\n",
    "if REQUIRE_CUTOFF:\n",
    "    before = len(X)\n",
    "    X = X[X[\"plies_processed\"] >= CUTOFF_PLIES].reset_index(drop=True)\n",
    "    kept = len(X)\n",
    "    print(f\"Kept games reaching {CUTOFF_PLIES} plies: {kept}/{before} ({kept/before:.1%})\")\n",
    "else:\n",
    "    print(\"Not filtering by cutoff (short games included).\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.6 Binary Task (drop draws)\n",
    "# ----------------------------------------------\n",
    "\n",
    "BINARY_TASK = True\n",
    "\n",
    "if BINARY_TASK:\n",
    "    before = len(X)\n",
    "    X = X[X[\"target\"].isin([\"white\", \"black\"])].reset_index(drop=True)\n",
    "    kept = len(X)\n",
    "    print(f\"Kept non-draws: {kept}/{before} ({kept/before:.1%})\")\n",
    "else:\n",
    "    print(\"Keeping draws (3-class task).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b02499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory before: 107.81 MB\n",
      "Memory after: 96.18 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_first30_san</th>\n",
       "      <th>plies_processed</th>\n",
       "      <th>cutoff_reached</th>\n",
       "      <th>captures_in_first_30_moves</th>\n",
       "      <th>checks_in_first_30_moves</th>\n",
       "      <th>target</th>\n",
       "      <th>white_elo</th>\n",
       "      <th>black_elo</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>elo_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtype</th>\n",
       "      <td>object</td>\n",
       "      <td>int8</td>\n",
       "      <td>int8</td>\n",
       "      <td>int8</td>\n",
       "      <td>int8</td>\n",
       "      <td>object</td>\n",
       "      <td>int16</td>\n",
       "      <td>int16</td>\n",
       "      <td>int16</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      moves_first30_san plies_processed cutoff_reached  \\\n",
       "dtype            object            int8           int8   \n",
       "\n",
       "      captures_in_first_30_moves checks_in_first_30_moves  target white_elo  \\\n",
       "dtype                       int8                     int8  object     int16   \n",
       "\n",
       "      black_elo elo_diff  elo_avg  \n",
       "dtype     int16    int16  float32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_first30_san</th>\n",
       "      <th>plies_processed</th>\n",
       "      <th>cutoff_reached</th>\n",
       "      <th>captures_in_first_30_moves</th>\n",
       "      <th>checks_in_first_30_moves</th>\n",
       "      <th>target</th>\n",
       "      <th>white_elo</th>\n",
       "      <th>black_elo</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>elo_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>black</td>\n",
       "      <td>2193</td>\n",
       "      <td>1782</td>\n",
       "      <td>411</td>\n",
       "      <td>1987.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>black</td>\n",
       "      <td>1548</td>\n",
       "      <td>1632</td>\n",
       "      <td>-84</td>\n",
       "      <td>1590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>black</td>\n",
       "      <td>1604</td>\n",
       "      <td>1918</td>\n",
       "      <td>-314</td>\n",
       "      <td>1761.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   moves_first30_san  plies_processed  \\\n",
       "0  d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...               60   \n",
       "1  e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...               60   \n",
       "2  d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...               60   \n",
       "\n",
       "   cutoff_reached  captures_in_first_30_moves  checks_in_first_30_moves  \\\n",
       "0               1                          13                         3   \n",
       "1               1                          17                         3   \n",
       "2               1                          12                         2   \n",
       "\n",
       "  target  white_elo  black_elo  elo_diff  elo_avg  \n",
       "0  black       2193       1782       411   1987.5  \n",
       "1  black       1548       1632       -84   1590.0  \n",
       "2  black       1604       1918      -314   1761.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. Impute & Downcast (sequence-only)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "\n",
    "def mem_mb(df):\n",
    "    return df.memory_usage(deep=True).sum() / (1024**2)\n",
    "\n",
    "print(f\"Memory before: {mem_mb(X):.2f} MB\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 5.1 Impute Numerics\n",
    "# ----------------------------------------------\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "for c in num_cols:\n",
    "    med = X[c].median()\n",
    "    X[c] = X[c].fillna(med)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 5.2 Downcast Numerics\n",
    "# ----------------------------------------------\n",
    "for c in num_cols:\n",
    "    if pd.api.types.is_integer_dtype(X[c]):\n",
    "        X[c] = pd.to_numeric(X[c], downcast=\"integer\")\n",
    "    elif pd.api.types.is_float_dtype(X[c]):\n",
    "        X[c] = pd.to_numeric(X[c], downcast=\"float\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 5.3 Preserve Sequence & Target Types\n",
    "# ----------------------------------------------\n",
    "X[MOVE_COL] = X[MOVE_COL].fillna(\"\").astype(str)\n",
    "X[\"target\"] = X[\"target\"].astype(str)\n",
    "\n",
    "print(f\"Memory after: {mem_mb(X):.2f} MB\")\n",
    "display(X.dtypes.to_frame(\"dtype\").T)\n",
    "display(X.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284c1b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution (counts):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "black    132587\n",
       "white    132435\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution (percent):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "black    50.03\n",
       "white    49.97\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values remaining\n",
      "Empty sequences: 0/265022\n",
      "At cutoff (60 plies): 265022/265022\n",
      "Over cutoff (> 60): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_first30_san</th>\n",
       "      <th>plies_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   moves_first30_san  plies_processed target\n",
       "0  d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...               60  black\n",
       "1  e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...               60  black\n",
       "2  d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...               60  black"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 6. Sanity Checks (leakage / balance / NAs / sequence)\n",
    "# ==============================================\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 6.1 Leakage Guard\n",
    "# ----------------------------------------------\n",
    "banned = {\n",
    "    \"Result\",\"result\",\"winner\",\"Winner\",\"termination\",\"Termination\",\n",
    "    \"num_moves\",\"NumMoves\",\"Opening\",\"opening\",\"ECO\",\"eco\",\"Moves\",\"AN\",\n",
    "    \"UTCDate\",\"UTCTime\",\"Event\",\"TimeControl\",\"White\",\"Black\",\n",
    "    \"WhiteElo\",\"BlackElo\",\"WhiteRatingDiff\",\"BlackRatingDiff\"\n",
    "}\n",
    "present_banned = [c for c in X.columns if c in banned]\n",
    "assert not present_banned, f\"Leaky columns present: {present_banned}\"\n",
    "assert MOVE_COL in X.columns\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 6.2 Class Balance\n",
    "# ----------------------------------------------\n",
    "print(\"Target distribution (counts):\")\n",
    "display(X[\"target\"].value_counts())\n",
    "print(\"Target distribution (percent):\")\n",
    "display((X[\"target\"].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 6.3 NA Audit\n",
    "# ----------------------------------------------\n",
    "na_counts = X.isna().sum()\n",
    "na_counts = na_counts[na_counts > 0]\n",
    "if not na_counts.empty:\n",
    "    print(\"Columns with missing values after imputation:\")\n",
    "    display(na_counts)\n",
    "else:\n",
    "    print(\"No missing values remaining\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 6.4 Sequence Checks\n",
    "# ----------------------------------------------\n",
    "total = len(X)\n",
    "empty_seq = (X[MOVE_COL].str.len() == 0).sum()\n",
    "at_cutoff = (X[\"plies_processed\"] == CUTOFF_PLIES).sum()\n",
    "over_cutoff = (X[\"plies_processed\"] > CUTOFF_PLIES).sum()\n",
    "\n",
    "print(f\"Empty sequences: {empty_seq}/{total}\")\n",
    "print(f\"At cutoff ({CUTOFF_PLIES} plies): {at_cutoff}/{total}\")\n",
    "print(f\"Over cutoff (> {CUTOFF_PLIES}): {over_cutoff}\")\n",
    "\n",
    "display(X[[MOVE_COL, \"plies_processed\", \"target\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5712d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV: E:\\Github Projects\\chess-outcome-prediction\\data\\chess_games_clean.csv\n",
      "Saved boards: E:\\Github Projects\\chess-outcome-prediction\\data\\chess_boards_8x8xC.npz shape: (265022, 8, 8, 36) dtype: uint8\n",
      "Saved meta: E:\\Github Projects\\chess-outcome-prediction\\data\\chess_games_clean_meta.json\n",
      "(265022, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_first30_san</th>\n",
       "      <th>plies_processed</th>\n",
       "      <th>cutoff_reached</th>\n",
       "      <th>captures_in_first_30_moves</th>\n",
       "      <th>checks_in_first_30_moves</th>\n",
       "      <th>target</th>\n",
       "      <th>white_elo</th>\n",
       "      <th>black_elo</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>elo_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>black</td>\n",
       "      <td>2193</td>\n",
       "      <td>1782</td>\n",
       "      <td>411</td>\n",
       "      <td>1987.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>black</td>\n",
       "      <td>1548</td>\n",
       "      <td>1632</td>\n",
       "      <td>-84</td>\n",
       "      <td>1590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>black</td>\n",
       "      <td>1604</td>\n",
       "      <td>1918</td>\n",
       "      <td>-314</td>\n",
       "      <td>1761.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   moves_first30_san  plies_processed  \\\n",
       "0  d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...               60   \n",
       "1  e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...               60   \n",
       "2  d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...               60   \n",
       "\n",
       "   cutoff_reached  captures_in_first_30_moves  checks_in_first_30_moves  \\\n",
       "0               1                          13                         3   \n",
       "1               1                          17                         3   \n",
       "2               1                          12                         2   \n",
       "\n",
       "  target  white_elo  black_elo  elo_diff  elo_avg  \n",
       "0  black       2193       1782       411   1987.5  \n",
       "1  black       1548       1632       -84   1590.0  \n",
       "2  black       1604       1918      -314   1761.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moves_first30_san â†’ fixed length: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves_first30_san</th>\n",
       "      <th>plies_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...</td>\n",
       "      <td>60</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   moves_first30_san  plies_processed target\n",
       "0  d4 Nf6 c4 e6 Nc3 c5 d5 d6 e3 e5 Nf3 Be7 Bd3 Nb...               60  black\n",
       "1  e4 e5 Nf3 Nc6 d4 Nxd4 Nxe5 Qe7 f4 d6 Qxd4 dxe5...               60  black\n",
       "2  d4 d5 c4 Nf6 Nc3 c6 Bg5 e6 Nf3 Be7 e3 O-O c5 h...               60  black"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 7. Save Cleaned Data & Metadata\n",
    "# ==============================================\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 7.1 Write CSV\n",
    "# ----------------------------------------------\n",
    "X.to_csv(CLEAN_CSV, index=False)\n",
    "print(\"Saved CSV:\", CLEAN_CSV)\n",
    "\n",
    "# Split SAN string into tokens and encode boards at CHECKPOINT_PLIES\n",
    "def _san_tokens(s): \n",
    "    return str(s).split()  # MOVE_COL already cleaned earlier\n",
    "\n",
    "boards = np.stack([boards_from_san_list(_san_tokens(s)) for s in X[MOVE_COL].tolist()], axis=0)\n",
    "np.savez_compressed(BOARDS_NPZ, boards=boards)\n",
    "print(\"Saved boards:\", BOARDS_NPZ, \"shape:\", boards.shape, \"dtype:\", boards.dtype)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 7.2 Write Metadata\n",
    "# ----------------------------------------------\n",
    "meta = {\n",
    "    \"cutoff_full_moves\": int(CUTOFF_FULL_MOVES),\n",
    "    \"cutoff_plies\": int(CUTOFF_PLIES),\n",
    "    \"rows\": int(len(X)),\n",
    "    \"columns\": list(X.columns),\n",
    "    \"move_col\": MOVE_COL,\n",
    "    \"captures_col\": CAPTURES_COL,\n",
    "    \"checks_col\": CHECKS_COL,\n",
    "    \"class_distribution\": X[\"target\"].value_counts().to_dict(),\n",
    "    \"boards_npz\": str(BOARDS_NPZ),\n",
    "    \"board_channels\": int(boards.shape[-1]),\n",
    "    \"board_checkpoints\": list(map(int, CHECKPOINT_PLIES)),\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(META_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(\"Saved meta:\", META_JSON)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 7.3 Quick Preview\n",
    "# ----------------------------------------------\n",
    "print(X.shape)\n",
    "display(X.head(3))\n",
    "assert MOVE_COL in X.columns\n",
    "assert X[\"plies_processed\"].max() <= CUTOFF_PLIES\n",
    "print(MOVE_COL, \"â†’ fixed length:\", CUTOFF_PLIES)\n",
    "display(X[[MOVE_COL, \"plies_processed\", \"target\"]].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361a42c",
   "metadata": {},
   "source": [
    "# CHESS OUTCOME PREDICTION â€” MODEL TRAINING\n",
    "\n",
    "**Goal**: train a binary classifier (*white vs. black*, draws removed) using token sequences of the opening plus optional Elo features.\n",
    "\n",
    "**Inputs**\n",
    "- Arrays: `X_train_seq`, `X_val_seq`, `X_test_seq` (padded token IDs), `y_*`.\n",
    "- *(Optional)* numeric features: `X_*_num` (e.g., `elo_diff`, `elo_avg`).\n",
    "- *(Optional)* `ds_train`, `ds_val`, `ds_test` (`tf.data`); otherwise they are built here.\n",
    "- Config/metadata: `SEQ_LEN`, `VOCAB_SIZE`, `NUM_NUMERIC`, `BATCH`, `EPOCHS`, `SEED`.\n",
    "\n",
    "**Model (two-branch)**\n",
    "- **Sequence branch**: `Embedding(VOCAB_SIZE, 128, mask_zero=True)` -> `Bidirectional(GRU(128, return_sequences=True))` -> `GlobalMaxPool1D` -> `Dropout(0.2)`.\n",
    "- **Numeric branch** *(if present)*: `LayerNormalization` -> `Dense(64, relu)` -> `Dropout(0.2)`.\n",
    "- **Head**: `Concatenate` -> `Dense(128, relu)` -> `Dropout(0.2)` -> `Dense(1, sigmoid)`.\n",
    "\n",
    "**Training**\n",
    "- Optimizer: `Adam` (clipnorm=1.0, lr=1e-3).  \n",
    "- Loss/metrics: `binary_crossentropy`, `accuracy`, `AUC`.\n",
    "- Callbacks: `EarlyStopping(patience=7, restore_best_weights=True)`,  \n",
    "  `ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-5)`,  \n",
    "  `ModelCheckpoint(save_best_only=True, monitor=\"val_loss\")`.\n",
    "- *(Optional)* `class_weight` for balance.  \n",
    "- Reproducibility: fixed `SEED`.\n",
    "\n",
    "**Evaluation**\n",
    "- Report **accuracy** and **macro-F1** on **val** and **test** (default threshold=0.5).\n",
    "- Grid-search the **best probability threshold** on the validation set; re-report test metrics at that threshold.\n",
    "- Show `classification_report` and **confusion matrix**.\n",
    "\n",
    "**Outputs (in `results/`)**\n",
    "- `best_seq_model.keras` - best weights by `val_loss`.\n",
    "- `label_mapping.json` - `{black: 0, white: 1}`.\n",
    "- `class_weights.json` - *(if used)*.\n",
    "- `seq_report.json` - metrics (val/test), confusion matrices, chosen threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 1. Imports & Paths\n",
    "# ==============================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.1 Config\n",
    "# ----------------------------------------------\n",
    "SEED = 42\n",
    "CUTOFF_FULL_MOVES = 30\n",
    "CUTOFF_PLIES = CUTOFF_FULL_MOVES * 2\n",
    "MOVE_COL = f\"moves_first{CUTOFF_FULL_MOVES}_san\"\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.2 Reproducibility\n",
    "# ----------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "globals().setdefault(\"BATCH\", 512)\n",
    "globals().setdefault(\"EPOCHS\", 40)\n",
    "\n",
    "\n",
    "print(\"Data:\", CLEAN_CSV)\n",
    "print(\"Meta:\", META_JSON)\n",
    "print(f\"Cutoff: {CUTOFF_FULL_MOVES} moves ({CUTOFF_PLIES} plies)\")\n",
    "print(\"Results dir:\", RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aec002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 2. Load, Tokenise, Split\n",
    "# ==============================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.1 Load\n",
    "# ----------------------------------------------\n",
    "df = pd.read_csv(CLEAN_CSV)\n",
    "expected = {MOVE_COL, \"plies_processed\", \"cutoff_reached\", \"target\"}\n",
    "missing = sorted(list(expected - set(df.columns)))\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "df = df.dropna(subset=[MOVE_COL, \"target\"]).reset_index(drop=True)\n",
    "df = df[df[MOVE_COL].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.2 Labels (binary: white vs black only)\n",
    "# ----------------------------------------------\n",
    "# Keep only non-draw games (should already be true after your 02 notebook change,\n",
    "# but this guards against stale CSVs)\n",
    "df = df[df[\"target\"].isin([\"black\", \"white\"])].reset_index(drop=True)\n",
    "\n",
    "CLASS_ORDER = [\"black\", \"white\"]   # id: 0 = black, 1 = white (keep this stable)\n",
    "label_to_id = {c:i for i,c in enumerate(CLASS_ORDER)}\n",
    "id_to_label = {i:c for c,i in label_to_id.items()}\n",
    "\n",
    "y = df[\"target\"].map(label_to_id).astype(\"int32\")\n",
    "assert set(np.unique(y)) == {0,1}, f\"Unexpected labels in y: {set(np.unique(y))}\"\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.3 Tokenise\n",
    "# ----------------------------------------------\n",
    "def to_tokens(s):\n",
    "    return str(s).split()\n",
    "\n",
    "tokens = df[MOVE_COL].apply(to_tokens)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.4 Split\n",
    "# ----------------------------------------------\n",
    "X_tmp, X_test_tok, y_tmp, y_test = train_test_split(\n",
    "    tokens, y, test_size=0.15, random_state=SEED, stratify=y\n",
    ")\n",
    "X_train_tok, X_val_tok, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.1765, random_state=SEED, stratify=y_tmp\n",
    ")  # 0.85 * 0.1765 â‰ˆ 0.15 â†’ 70/15/15\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.5 Vocab (train only)\n",
    "# ----------------------------------------------\n",
    "counter = Counter(t for seq in X_train_tok for t in seq[:CUTOFF_PLIES])\n",
    "vocab = [\"<PAD>\", \"<UNK>\"] + [tok for tok, _ in counter.most_common()]\n",
    "stoi = {t:i for i,t in enumerate(vocab)}\n",
    "PAD_ID, UNK_ID = 0, 1\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.6 Numericalise\n",
    "# ----------------------------------------------\n",
    "def to_ids(seq, max_len=CUTOFF_PLIES):\n",
    "    ids = [stoi.get(t, UNK_ID) for t in seq[:max_len]]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [PAD_ID] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int32)\n",
    "\n",
    "X_train_seq = np.stack([to_ids(s) for s in X_train_tok])\n",
    "X_val_seq   = np.stack([to_ids(s) for s in X_val_tok])\n",
    "X_test_seq  = np.stack([to_ids(s) for s in X_test_tok])\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.7 Class Weights\n",
    "# ----------------------------------------------\n",
    "classes = np.array(sorted(label_to_id.values()))\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.8 Persist Artifacts\n",
    "# ----------------------------------------------\n",
    "(RESULTS_DIR / \"vocab.json\").write_text(json.dumps({\"vocab\": vocab}, ensure_ascii=False))\n",
    "(RESULTS_DIR / \"label_mapping.json\").write_text(json.dumps({\"label_to_id\": label_to_id, \"id_to_label\": id_to_label}, indent=2))\n",
    "(RESULTS_DIR / \"class_weights.json\").write_text(json.dumps(class_weight, indent=2))\n",
    "(RESULTS_DIR / \"dl_config.json\").write_text(json.dumps({\"cutoff_full_moves\": CUTOFF_FULL_MOVES, \"cutoff_plies\": CUTOFF_PLIES, \"pad_id\": PAD_ID, \"unk_id\": UNK_ID}, indent=2))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.9 Summary\n",
    "# ----------------------------------------------\n",
    "print(\"Shapes:\", X_train_seq.shape, X_val_seq.shape, X_test_seq.shape)\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "print(\"Label map:\", label_to_id)\n",
    "print(\"Class weights:\", class_weight)\n",
    "print(\"Samples (train/val/test):\", len(X_train_seq), len(X_val_seq), len(X_test_seq))\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2.10 Numeric features (Elo) â€” standardise on train only\n",
    "# -----------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Load board tensors, align with splits ---\n",
    "boards_all = np.load(BOARDS_NPZ)[\"boards\"]  # (N, 8, 8, C)\n",
    "C_BOARDS = int(boards_all.shape[-1])\n",
    "\n",
    "X_train_board = boards_all[X_train_tok.index].astype(\"float32\")  # (B,8,8,C)\n",
    "X_val_board   = boards_all[X_val_tok.index].astype(\"float32\")\n",
    "X_test_board  = boards_all[X_test_tok.index].astype(\"float32\")\n",
    "\n",
    "print(\"Board shapes:\", X_train_board.shape, X_val_board.shape, X_test_board.shape)\n",
    "\n",
    "# Default to 4 ELO features if not set above in 1.3 Paths\n",
    "ELO_FEATS = [\"elo_diff\", \"elo_avg\", \"white_elo\", \"black_elo\"] if \"ELO_FEATS\" not in globals() else ELO_FEATS\n",
    "missing = [c for c in ELO_FEATS if c not in df.columns]\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "X_train_num = df.loc[X_train_tok.index, ELO_FEATS].astype(\"float32\").values\n",
    "X_val_num   = df.loc[X_val_tok.index,   ELO_FEATS].astype(\"float32\").values\n",
    "X_test_num  = df.loc[X_test_tok.index,  ELO_FEATS].astype(\"float32\").values\n",
    "\n",
    "num_scaler = StandardScaler().fit(X_train_num)\n",
    "X_train_num = num_scaler.transform(X_train_num).astype(\"float32\")\n",
    "X_val_num   = num_scaler.transform(X_val_num).astype(\"float32\")\n",
    "X_test_num  = num_scaler.transform(X_test_num).astype(\"float32\")\n",
    "\n",
    "print(\"Seq shapes:\", X_train_seq.shape, X_val_seq.shape, X_test_seq.shape)\n",
    "print(\"Num shapes:\", X_train_num.shape,  X_val_num.shape,  X_test_num.shape)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.11 Label sanity (binary) â€” class weights OFF\n",
    "# ----------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "y_train = np.asarray(y_train, dtype=np.int32)\n",
    "y_val   = np.asarray(y_val,   dtype=np.int32)\n",
    "y_test  = np.asarray(y_test,  dtype=np.int32)\n",
    "\n",
    "valid_classes = np.array([0, 1], dtype=np.int32)\n",
    "for split_name, yy in [(\"train\", y_train), (\"val\", y_val), (\"test\", y_test)]:\n",
    "    extra = np.setdiff1d(np.unique(yy), valid_classes)\n",
    "    assert extra.size == 0, f\"{split_name} has unexpected labels: {extra}\"\n",
    "\n",
    "# Disable class weighting (classes are ~balanced after removing draws)\n",
    "class_weight = None\n",
    "\n",
    "print(\"Label uniques:\", {k: sorted(np.unique(v).tolist())\n",
    "                         for k, v in {\"train\": y_train, \"val\": y_val, \"test\": y_test}.items()})\n",
    "print(\"class_weight:\", class_weight)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.12 Build tf.data datasets (binary, no oversampling)\n",
    "# ----------------------------------------------\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH = 512 if \"BATCH\" not in globals() else BATCH\n",
    "\n",
    "train_inputs = (X_train_seq, X_train_num, X_train_board)\n",
    "val_inputs   = (X_val_seq,   X_val_num,   X_val_board)\n",
    "test_inputs  = (X_test_seq,  X_test_num,  X_test_board)\n",
    "\n",
    "ds_train = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_inputs, y_train))\n",
    "    .shuffle(200_000, seed=SEED)\n",
    "    .batch(BATCH)\n",
    "    .prefetch(2)\n",
    ")\n",
    "ds_val  = tf.data.Dataset.from_tensor_slices((val_inputs,  y_val )).batch(BATCH).prefetch(2)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_inputs, y_test)).batch(BATCH)\n",
    "\n",
    "print(\"Binary two-input training dataset ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3 Â· Model Training (Binary: white vs black, draws removed)\n",
    "# ============================================================\n",
    "import os, json, numpy as np, tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------\n",
    "# Reproducibility & paths\n",
    "# -------------------------\n",
    "SEED = globals().get(\"SEED\", 42)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = globals().get(\"RESULTS_DIR\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "BEST_MODEL_PATH = os.path.join(RESULTS_DIR, \"best_seq_model.keras\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Expect the following to already exist from earlier notebook cells\n",
    "#   - X_train_seq, X_val_seq, X_test_seq  (int token ids, padded)\n",
    "#   - X_train_num, X_val_num, X_test_num  (float numeric features)\n",
    "#   - X_train_board, X_val_board, X_test_board  (8x8xC board tensors)\n",
    "#   - y_train, y_val, y_test              (0=black, 1=white)\n",
    "#   - ds_train, ds_val, ds_test           (tf.data datasets)  [optional]\n",
    "#   - CLASS_ORDER = [\"black\",\"white\"]\n",
    "# ----------------------------------------------------------------\n",
    "for name in [\"X_train_seq\",\"X_val_seq\",\"X_test_seq\",\n",
    "             \"X_train_num\",\"X_val_num\",\"X_test_num\",\n",
    "             \"X_train_board\",\"X_val_board\",\"X_test_board\",\n",
    "             \"y_train\",\"y_val\",\"y_test\"]:\n",
    "    assert name in globals(), f\"Missing expected variable: {name}\"\n",
    "\n",
    "SEQ_LEN = int(X_train_seq.shape[1])\n",
    "NUM_NUMERIC = int(X_train_num.shape[1]) if len(X_train_num.shape) == 2 else 0\n",
    "C_BOARDS = int(X_train_board.shape[-1])\n",
    "\n",
    "# Infer vocab size safely from training IDs (works even if vocab.json not loaded here)\n",
    "VOCAB_SIZE = int(np.max(X_train_seq)) + 1\n",
    "assert VOCAB_SIZE > 1, \"VOCAB_SIZE must be > 1\"\n",
    "\n",
    "# -------------------------\n",
    "# tf.data (if not provided)\n",
    "# -------------------------\n",
    "if \"ds_train\" not in globals():\n",
    "    BATCH = 512\n",
    "    train_inputs = (X_train_seq, X_train_num, X_train_board)\n",
    "    val_inputs   = (X_val_seq,   X_val_num,   X_val_board)\n",
    "    test_inputs  = (X_test_seq,  X_test_num,  X_test_board)\n",
    "\n",
    "    ds_train = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((train_inputs, y_train))\n",
    "        .shuffle(200_000, seed=SEED)\n",
    "        .batch(BATCH)\n",
    "        .prefetch(2)\n",
    "    )\n",
    "    ds_val = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((val_inputs, y_val))\n",
    "        .batch(BATCH)\n",
    "        .prefetch(2)\n",
    "    )\n",
    "    ds_test = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((test_inputs, y_test))\n",
    "        .batch(BATCH)\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Model backbone\n",
    "# -------------------------\n",
    "EMB = 128\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Sequence branch\n",
    "seq_in = layers.Input(shape=(SEQ_LEN,), dtype=\"int32\", name=\"seq_in\")\n",
    "x = layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMB, mask_zero=True, name=\"tok_emb\")(seq_in)\n",
    "x = layers.Bidirectional(layers.GRU(128, return_sequences=True), name=\"bi_gru\")(x)\n",
    "x = layers.GlobalMaxPool1D(name=\"gmp\")(x)\n",
    "x = layers.Dropout(DROPOUT)(x)\n",
    "\n",
    "# Numeric branch (optional)\n",
    "if NUM_NUMERIC > 0:\n",
    "    num_in = layers.Input(shape=(NUM_NUMERIC,), dtype=\"float32\", name=\"num_in\")\n",
    "    n = layers.LayerNormalization()(num_in)\n",
    "    n = layers.Dense(64, activation=\"relu\")(n)\n",
    "    n = layers.Dropout(DROPOUT)(n)\n",
    "else:\n",
    "    num_in, n = None, None\n",
    "\n",
    "# Board CNN branch (compact)\n",
    "brd_in = layers.Input(shape=(8, 8, C_BOARDS), dtype=\"float32\", name=\"brd_in\")\n",
    "z = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(brd_in)\n",
    "z = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(z)\n",
    "z = layers.GlobalAveragePooling2D()(z)\n",
    "z = layers.Dropout(DROPOUT)(z)\n",
    "\n",
    "# Fuse\n",
    "if NUM_NUMERIC > 0:\n",
    "    fused = layers.Concatenate()([x, n, z])\n",
    "    inputs = [seq_in, num_in, brd_in]\n",
    "else:\n",
    "    fused = layers.Concatenate()([x, z])\n",
    "    inputs = [seq_in, brd_in]\n",
    "\n",
    "# Head\n",
    "fused = layers.Dense(128, activation=\"relu\")(fused)\n",
    "fused = layers.Dropout(DROPOUT)(fused)\n",
    "out = layers.Dense(1, activation=\"sigmoid\", name=\"out\")(fused)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "# -------------------------\n",
    "# Compile\n",
    "# -------------------------\n",
    "opt = tf.keras.optimizers.AdamW(learning_rate=8e-4, weight_decay=1e-4, clipnorm=1.0)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
    "\n",
    "# -------------------------\n",
    "# Callbacks\n",
    "# -------------------------\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(BEST_MODEL_PATH, monitor=\"val_auc\", mode=\"max\", save_best_only=True),\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Train\n",
    "# -------------------------\n",
    "EPOCHS = globals().get(\"EPOCHS\", 40)\n",
    "\n",
    "cw = None  # class weights OFF (balanced binary)\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=cw,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation helpers\n",
    "# -------------------------\n",
    "def eval_ds(m, ds, y_true, name, thr=0.5):\n",
    "    y_prob = m.predict(ds, verbose=0).ravel()\n",
    "    y_pred = (y_prob >= thr).astype(\"int32\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    rep = classification_report(y_true, y_pred, target_names=CLASS_ORDER, zero_division=0)\n",
    "    cm  = confusion_matrix(y_true, y_pred).tolist()\n",
    "    print(f\"[{name}] acc={acc:.4f}  f1_macro={f1m:.4f}\")\n",
    "    print(rep)\n",
    "    return {\"acc\": acc, \"f1_macro\": f1m, \"cm\": cm}\n",
    "\n",
    "print(\"\\n--- Validation ---\")\n",
    "val_stats  = eval_ds(model, ds_val,  y_val,  \"val\",  thr=0.5)\n",
    "\n",
    "print(\"\\n--- Test ---\")\n",
    "test_stats = eval_ds(model, ds_test, y_test, \"test\", thr=0.5)\n",
    "\n",
    "# ---- Threshold sweep on validation ----\n",
    "val_prob  = model.predict(ds_val,  verbose=0).ravel()\n",
    "test_prob = model.predict(ds_test, verbose=0).ravel()\n",
    "\n",
    "ths = np.linspace(0.30, 0.70, 41)\n",
    "def _stats(y_true, prob, thr):\n",
    "    pred = (prob >= thr).astype(\"int32\")\n",
    "    return accuracy_score(y_true, pred), f1_score(y_true, pred, average=\"macro\")\n",
    "\n",
    "best_i   = int(np.argmax([_stats(y_val, val_prob, t)[0] for t in ths]))\n",
    "best_thr = float(ths[best_i])\n",
    "val_acc,  val_f1  = _stats(y_val,  val_prob,  best_thr)\n",
    "test_acc, test_f1 = _stats(y_test, test_prob, best_thr)\n",
    "\n",
    "print(f\"\\nBest threshold = {best_thr:.3f} \"\n",
    "      f\"(val acc={val_acc:.4f}, f1={val_f1:.4f}); \"\n",
    "      f\"test@best acc={test_acc:.4f}, f1={test_f1:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Save lightweight artefacts\n",
    "# -------------------------\n",
    "# Label mapping (2-class)\n",
    "label_mapping = {\"black\": 0, \"white\": 1}\n",
    "with open(os.path.join(RESULTS_DIR, \"label_mapping.json\"), \"w\") as f:\n",
    "    json.dump(label_mapping, f, indent=2)\n",
    "\n",
    "# Class weights (if any)\n",
    "if cw is not None:\n",
    "    with open(os.path.join(RESULTS_DIR, \"class_weights.json\"), \"w\") as f:\n",
    "        json.dump({int(k): float(v) for k, v in cw.items()}, f, indent=2)\n",
    "\n",
    "# Simple metrics record\n",
    "with open(os.path.join(RESULTS_DIR, \"seq_report.json\"), \"w\") as f:\n",
    "    json.dump({\"val\": val_stats, \"test\": test_stats}, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved best model to:\", BEST_MODEL_PATH)\n",
    "print(\"Saved label_mapping.json, class_weights.json (if used), and seq_report.json to:\", RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4 Â· Final Evaluation & Plots (val + test)\n",
    "# ============================================================\n",
    "import os, json, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "\n",
    "RESULTS_DIR = globals().get(\"RESULTS_DIR\", \"results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# 4.1 Predict probabilities\n",
    "# -------------------------\n",
    "val_prob  = model.predict(ds_val,  verbose=0).ravel()\n",
    "test_prob = model.predict(ds_test, verbose=0).ravel()\n",
    "\n",
    "# -------------------------\n",
    "# 4.2 Pick threshold (by val accuracy; also show best by F1)\n",
    "# -------------------------\n",
    "def best_thr(y_true, prob, metric=\"acc\"):\n",
    "    grid = np.linspace(0.05, 0.95, 181)  # step=0.005\n",
    "    best_t, best_s = 0.5, -1.0\n",
    "    for t in grid:\n",
    "        y_hat = (prob >= t).astype(\"int32\")\n",
    "        s = accuracy_score(y_true, y_hat) if metric==\"acc\" else f1_score(y_true, y_hat, average=\"macro\")\n",
    "        if s > best_s:\n",
    "            best_t, best_s = t, s\n",
    "    return float(best_t), float(best_s)\n",
    "\n",
    "best_t_acc, best_acc = best_thr(y_val, val_prob, \"acc\")\n",
    "best_t_f1,  best_f1  = best_thr(y_val, val_prob, \"f1\")\n",
    "\n",
    "THR = best_t_acc  # use accuracy-optimal threshold for reports\n",
    "\n",
    "# -------------------------\n",
    "# 4.3 Reports & confusion matrices\n",
    "# -------------------------\n",
    "def eval_at(y_true, prob, name, thr):\n",
    "    y_pred = (prob >= thr).astype(\"int32\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    rep = classification_report(y_true, y_pred, target_names=CLASS_ORDER, zero_division=0)\n",
    "    cm  = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"[{name}] thr={thr:.3f}  acc={acc:.4f}  f1_macro={f1m:.4f}\")\n",
    "    print(rep)\n",
    "    return acc, f1m, cm, y_pred\n",
    "\n",
    "val_acc,  val_f1,  val_cm,  val_pred  = eval_at(y_val,  val_prob,  \"val\",  THR)\n",
    "test_acc, test_f1, test_cm, test_pred = eval_at(y_test, test_prob, \"test\", THR)\n",
    "print(f\"Best thr by acc: {best_t_acc:.3f} (val acc={best_acc:.4f}) | by F1: {best_t_f1:.3f} (val f1={best_f1:.4f})\")\n",
    "\n",
    "# -------------------------\n",
    "# 4.4 Plots (saved to results/)\n",
    "# -------------------------\n",
    "def plot_roc_pr():\n",
    "    # ROC\n",
    "    fpr_v, tpr_v, _ = roc_curve(y_val,  val_prob)\n",
    "    fpr_t, tpr_t, _ = roc_curve(y_test, test_prob)\n",
    "    auc_v, auc_t = auc(fpr_v, tpr_v), auc(fpr_t, tpr_t)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_v, tpr_v, label=f\"val AUC={auc_v:.3f}\")\n",
    "    plt.plot(fpr_t, tpr_t, label=f\"test AUC={auc_t:.3f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"ROC\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"roc.png\"), dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "    # PR\n",
    "    p_v, r_v, _ = precision_recall_curve(y_val,  val_prob)\n",
    "    p_t, r_t, _ = precision_recall_curve(y_test, test_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(r_v, p_v, label=\"val\")\n",
    "    plt.plot(r_t, p_t, label=\"test\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precisionâ€“Recall\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"pr.png\"), dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "def plot_prob_hists():\n",
    "    plt.figure()\n",
    "    plt.hist(val_prob[y_val==0], bins=40, density=True, histtype=\"step\", label=\"val / black\")\n",
    "    plt.hist(val_prob[y_val==1], bins=40, density=True, histtype=\"step\", label=\"val / white\")\n",
    "    plt.axvline(THR, linestyle=\"--\", label=f\"thr={THR:.3f}\")\n",
    "    plt.xlabel(\"Predicted P(white)\"); plt.ylabel(\"Density\"); plt.title(\"Val probability distribution\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"val_prob_hist.png\"), dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "def plot_cm(cm, title, fname):\n",
    "    plt.figure()\n",
    "    im = plt.imshow(cm, aspect=\"equal\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(CLASS_ORDER))\n",
    "    plt.xticks(ticks, CLASS_ORDER); plt.yticks(ticks, CLASS_ORDER)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(title)\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(RESULTS_DIR, fname), dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_pr()\n",
    "plot_prob_hists()\n",
    "plot_cm(val_cm,  f\"Confusion Matrix (val) @ thr={THR:.3f}\",  \"cm_val.png\")\n",
    "plot_cm(test_cm, f\"Confusion Matrix (test) @ thr={THR:.3f}\", \"cm_test.png\")\n",
    "\n",
    "# -------------------------\n",
    "# 4.5 Training curves (if available)\n",
    "# -------------------------\n",
    "if \"history\" in globals():\n",
    "    H = history.history\n",
    "    def curve(keys, title, fname):\n",
    "        keys = [k for k in keys if k in H]\n",
    "        if not keys: return\n",
    "        plt.figure()\n",
    "        for k in keys: plt.plot(H[k], label=k)\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Value\"); plt.title(title)\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(RESULTS_DIR, fname), dpi=160)\n",
    "        plt.show()\n",
    "\n",
    "    curve([\"loss\",\"val_loss\"], \"Loss\", \"loss_curves.png\")\n",
    "    curve([\"accuracy\",\"val_accuracy\"], \"Accuracy\", \"acc_curves.png\")\n",
    "    curve([\"auc\",\"val_auc\"], \"AUC\", \"auc_curves.png\")\n",
    "\n",
    "# -------------------------\n",
    "# 4.6 Persist summary\n",
    "# -------------------------\n",
    "summary = {\n",
    "    \"threshold\": THR,\n",
    "    \"val\":  {\"acc\": val_acc,  \"f1_macro\": val_f1,  \"cm\": val_cm.tolist()},\n",
    "    \"test\": {\"acc\": test_acc, \"f1_macro\": test_f1, \"cm\": test_cm.tolist()},\n",
    "    \"best_thr_by_acc\": {\"thr\": best_t_acc, \"val_acc\": best_acc},\n",
    "    \"best_thr_by_f1\":  {\"thr\": best_t_f1,  \"val_f1\":  best_f1},\n",
    "}\n",
    "with open(os.path.join(RESULTS_DIR, \"final_summary.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Saved plots and summary to:\", RESULTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

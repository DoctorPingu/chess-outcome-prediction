{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ad6c96",
   "metadata": {},
   "source": [
    "# Chess Outcome — Model Training\n",
    "\n",
    "**Purpose:** Train deep-learning models to predict the game result from early-game move sequences (first *N* full moves, as configured).\n",
    "\n",
    "**Inputs:** Clean dataset from Notebook 2 (sequence column + target).\n",
    "\n",
    "**Process:** Load & tokenise → build vocab from train only → pad/truncate to the configured length → stratified split → train model(s) with early stopping and LR scheduling → handle class imbalance (balanced batches or class weights) → evaluate and save artefacts.\n",
    "\n",
    "**Metrics:** Accuracy, Macro-F1, and confusion matrix.\n",
    "\n",
    "**Outputs:** Best model (`results/*.keras`) and run report (`results/seq_report.json`). Seed fixed; GPU used if available (mixed precision optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f594bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: E:\\Github Projects\\chess-outcome-prediction\\data\\chess_games_clean.csv\n",
      "Meta: E:\\Github Projects\\chess-outcome-prediction\\data\\chess_games_clean_meta.json\n",
      "Cutoff: 30 moves (60 plies)\n",
      "Results dir: E:\\Github Projects\\chess-outcome-prediction\\results\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1. Imports & Paths\n",
    "# ==============================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.1 Config\n",
    "# ----------------------------------------------\n",
    "SEED = 42\n",
    "CUTOFF_FULL_MOVES = 30\n",
    "CUTOFF_PLIES = CUTOFF_FULL_MOVES * 2\n",
    "MOVE_COL = f\"moves_first{CUTOFF_FULL_MOVES}_san\"\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.2 Reproducibility\n",
    "# ----------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.3 Paths\n",
    "# ----------------------------------------------\n",
    "NB_DIR = Path.cwd()\n",
    "DATA_DIR = (NB_DIR / \"../data\").resolve()\n",
    "RESULTS_DIR = (NB_DIR / \"../results\").resolve()\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ELO_FEATS = [\"elo_diff\", \"elo_avg\"]\n",
    "\n",
    "CLEAN_CSV = DATA_DIR / \"chess_games_clean.csv\"\n",
    "META_JSON = DATA_DIR / \"chess_games_clean_meta.json\"\n",
    "\n",
    "print(\"Data:\", CLEAN_CSV)\n",
    "print(\"Meta:\", META_JSON)\n",
    "print(f\"Cutoff: {CUTOFF_FULL_MOVES} moves ({CUTOFF_PLIES} plies)\")\n",
    "print(\"Results dir:\", RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e6216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (99608, 60) (21349, 60) (21346, 60)\n",
      "Vocab size: 6809\n",
      "Label map: {'black': 0, 'draw': 1, 'white': 2}\n",
      "Class weights: {0: 0.7208725041070511, 1: 8.601727115716754, 2: 0.6682095970268402}\n",
      "Samples (train/val/test): 99608 21349 21346\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Load, Tokenise, Split\n",
    "# ==============================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.1 Load\n",
    "# ----------------------------------------------\n",
    "df = pd.read_csv(CLEAN_CSV)\n",
    "expected = {MOVE_COL, \"plies_processed\", \"cutoff_reached\", \"target\"}\n",
    "missing = sorted(list(expected - set(df.columns)))\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "df = df.dropna(subset=[MOVE_COL, \"target\"]).reset_index(drop=True)\n",
    "df = df[df[MOVE_COL].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.2 Labels\n",
    "# ----------------------------------------------\n",
    "CLASS_ORDER = [\"black\", \"draw\", \"white\"]\n",
    "label_to_id = {c:i for i,c in enumerate(CLASS_ORDER)}\n",
    "id_to_label = {i:c for c,i in label_to_id.items()}\n",
    "y = df[\"target\"].map(label_to_id)\n",
    "mask = y.notna()\n",
    "df, y = df[mask].reset_index(drop=True), y[mask].astype(int).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.3 Tokenise\n",
    "# ----------------------------------------------\n",
    "def to_tokens(s):\n",
    "    return str(s).split()\n",
    "\n",
    "tokens = df[MOVE_COL].apply(to_tokens)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.4 Split\n",
    "# ----------------------------------------------\n",
    "X_tmp, X_test_tok, y_tmp, y_test = train_test_split(\n",
    "    tokens, y, test_size=0.15, random_state=SEED, stratify=y\n",
    ")\n",
    "X_train_tok, X_val_tok, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.1765, random_state=SEED, stratify=y_tmp\n",
    ")  # 0.85 * 0.1765 ≈ 0.15 → 70/15/15\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.5 Vocab (train only)\n",
    "# ----------------------------------------------\n",
    "counter = Counter(t for seq in X_train_tok for t in seq[:CUTOFF_PLIES])\n",
    "vocab = [\"<PAD>\", \"<UNK>\"] + [tok for tok, _ in counter.most_common()]\n",
    "stoi = {t:i for i,t in enumerate(vocab)}\n",
    "PAD_ID, UNK_ID = 0, 1\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.6 Numericalise\n",
    "# ----------------------------------------------\n",
    "def to_ids(seq, max_len=CUTOFF_PLIES):\n",
    "    ids = [stoi.get(t, UNK_ID) for t in seq[:max_len]]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [PAD_ID] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int32)\n",
    "\n",
    "X_train_seq = np.stack([to_ids(s) for s in X_train_tok])\n",
    "X_val_seq   = np.stack([to_ids(s) for s in X_val_tok])\n",
    "X_test_seq  = np.stack([to_ids(s) for s in X_test_tok])\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.7 Class Weights\n",
    "# ----------------------------------------------\n",
    "classes = np.array(sorted(label_to_id.values()))\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.8 Persist Artifacts\n",
    "# ----------------------------------------------\n",
    "(RESULTS_DIR / \"vocab.json\").write_text(json.dumps({\"vocab\": vocab}, ensure_ascii=False))\n",
    "(RESULTS_DIR / \"label_mapping.json\").write_text(json.dumps({\"label_to_id\": label_to_id, \"id_to_label\": id_to_label}, indent=2))\n",
    "(RESULTS_DIR / \"class_weights.json\").write_text(json.dumps(class_weight, indent=2))\n",
    "(RESULTS_DIR / \"dl_config.json\").write_text(json.dumps({\"cutoff_full_moves\": CUTOFF_FULL_MOVES, \"cutoff_plies\": CUTOFF_PLIES, \"pad_id\": PAD_ID, \"unk_id\": UNK_ID}, indent=2))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.9 Summary\n",
    "# ----------------------------------------------\n",
    "print(\"Shapes:\", X_train_seq.shape, X_val_seq.shape, X_test_seq.shape)\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "print(\"Label map:\", label_to_id)\n",
    "print(\"Class weights:\", class_weight)\n",
    "print(\"Samples (train/val/test):\", len(X_train_seq), len(X_val_seq), len(X_test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1074d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq shapes: (99608, 60) (21349, 60) (21346, 60)\n",
      "Num shapes: (99608, 2) (21349, 2) (21346, 2)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2.10 Numeric features (Elo) — standardise on train only\n",
    "# ==============================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ELO_FEATS = [\"elo_diff\", \"elo_avg\"] if \"ELO_FEATS\" not in globals() else ELO_FEATS\n",
    "assert all(f in df.columns for f in ELO_FEATS), f\"Missing columns: {set(ELO_FEATS)-set(df.columns)}\"\n",
    "\n",
    "X_train_num = df.loc[X_train_tok.index, ELO_FEATS].astype(\"float32\").values\n",
    "X_val_num   = df.loc[X_val_tok.index,   ELO_FEATS].astype(\"float32\").values\n",
    "X_test_num  = df.loc[X_test_tok.index,  ELO_FEATS].astype(\"float32\").values\n",
    "\n",
    "num_scaler = StandardScaler().fit(X_train_num)\n",
    "X_train_num = num_scaler.transform(X_train_num)\n",
    "X_val_num   = num_scaler.transform(X_val_num)\n",
    "X_test_num  = num_scaler.transform(X_test_num)\n",
    "\n",
    "print(\"Seq shapes:\", X_train_seq.shape, X_val_seq.shape, X_test_seq.shape)\n",
    "print(\"Num shapes:\", X_train_num.shape, X_val_num.shape, X_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac563f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label uniques: {'train': [0, 1, 2], 'val': [0, 1, 2], 'test': [0, 1, 2]}\n",
      "class_weight keys: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2.11 Label sanity & class weights (robust)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "NUM_CLASSES = len(CLASS_ORDER)\n",
    "\n",
    "def to_np_int(a):\n",
    "    return np.asarray(a, dtype=np.int32)\n",
    "\n",
    "y_train = to_np_int(y_train)\n",
    "y_val   = to_np_int(y_val)\n",
    "y_test  = to_np_int(y_test)\n",
    "\n",
    "valid_classes = np.arange(NUM_CLASSES, dtype=np.int32)\n",
    "extra_train = np.setdiff1d(np.unique(y_train), valid_classes)\n",
    "extra_val   = np.setdiff1d(np.unique(y_val),   valid_classes)\n",
    "extra_test  = np.setdiff1d(np.unique(y_test),  valid_classes)\n",
    "assert extra_train.size == 0 and extra_val.size == 0 and extra_test.size == 0, \\\n",
    "    f\"Unexpected labels found. Train:{extra_train}, Val:{extra_val}, Test:{extra_test}\"\n",
    "\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=valid_classes, y=y_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(valid_classes, cw)}\n",
    "\n",
    "print(\"Label uniques:\",\n",
    "      {k: sorted(np.unique(v).tolist()) for k, v in\n",
    "       {\"train\": y_train, \"val\": y_val, \"test\": y_test}.items()})\n",
    "print(\"class_weight keys:\", list(class_weight.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30024a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced two-input training dataset ready.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2.12 Build tf.data datasets (balanced training)\n",
    "# ==============================================\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH = 512 if \"BATCH\" not in globals() else BATCH\n",
    "OVERSAMPLE_DRAWS = 6 if \"OVERSAMPLE_DRAWS\" not in globals() else OVERSAMPLE_DRAWS\n",
    "\n",
    "train_seq = tf.constant(X_train_seq)\n",
    "train_num = tf.constant(X_train_num)\n",
    "train_lbl = tf.constant(y_train)\n",
    "\n",
    "draw_id = label_to_id[\"draw\"]\n",
    "blk_id  = label_to_id[\"black\"]\n",
    "wht_id  = label_to_id[\"white\"]\n",
    "\n",
    "draw_idx = tf.where(train_lbl == draw_id)[:, 0]\n",
    "blk_idx  = tf.where(train_lbl == blk_id)[:, 0]\n",
    "wht_idx  = tf.where(train_lbl == wht_id)[:, 0]\n",
    "\n",
    "def ds_from_indices(idx):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        ((tf.gather(train_seq, idx), tf.gather(train_num, idx)),\n",
    "         tf.gather(train_lbl, idx))\n",
    "    )\n",
    "\n",
    "ds_train = (\n",
    "    ds_from_indices(blk_idx)\n",
    "    .concatenate(ds_from_indices(wht_idx))\n",
    "    .concatenate(ds_from_indices(draw_idx).repeat(OVERSAMPLE_DRAWS))\n",
    "    .shuffle(200_000, seed=SEED)\n",
    "    .batch(BATCH)\n",
    "    .prefetch(2)\n",
    ")\n",
    "\n",
    "ds_val  = tf.data.Dataset.from_tensor_slices(((X_val_seq,  X_val_num),  y_val )).batch(BATCH).prefetch(2)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(((X_test_seq, X_test_num), y_test)).batch(BATCH)\n",
    "\n",
    "print(\"Balanced two-input training dataset ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be892677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ seq_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">871,552</span> │ seq_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ seq_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ num_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ seq_in (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m871,552\u001b[0m │ seq_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ seq_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m263,168\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m394,240\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_in (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ num_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m96\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m20,608\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,582,951</span> (6.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,582,951\u001b[0m (6.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,582,951</span> (6.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,582,951\u001b[0m (6.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 572ms/step - accuracy: 0.4903 - loss: 0.9821 - val_accuracy: 0.5759 - val_loss: 0.8010 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 314ms/step - accuracy: 0.5961 - loss: 0.8163 - val_accuracy: 0.5548 - val_loss: 0.8309 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.6393 - loss: 0.7387\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 376ms/step - accuracy: 0.6393 - loss: 0.7387 - val_accuracy: 0.5369 - val_loss: 0.8531 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 338ms/step - accuracy: 0.6782 - loss: 0.6577 - val_accuracy: 0.5798 - val_loss: 0.9195 - learning_rate: 5.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.7048 - loss: 0.6058\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 335ms/step - accuracy: 0.7048 - loss: 0.6058 - val_accuracy: 0.5761 - val_loss: 1.0010 - learning_rate: 5.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 333ms/step - accuracy: 0.7252 - loss: 0.5593 - val_accuracy: 0.5885 - val_loss: 1.0800 - learning_rate: 2.5000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.7356 - loss: 0.5291\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 363ms/step - accuracy: 0.7356 - loss: 0.5291 - val_accuracy: 0.5906 - val_loss: 1.1607 - learning_rate: 2.5000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 401ms/step - accuracy: 0.7460 - loss: 0.5046 - val_accuracy: 0.6000 - val_loss: 1.2655 - learning_rate: 1.2500e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.7521 - loss: 0.4847\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 388ms/step - accuracy: 0.7521 - loss: 0.4847 - val_accuracy: 0.6035 - val_loss: 1.3199 - learning_rate: 1.2500e-04\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "[Validation] acc=0.5759  f1_macro=0.4561\n",
      "[Test] acc=0.5791  f1_macro=0.4603\n",
      "Saved: E:\\Github Projects\\chess-outcome-prediction\\results\\seq_report.json\n",
      "Best model: E:\\Github Projects\\chess-outcome-prediction\\results\\best_seq_model.keras\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 3. Model · Train (balanced) · Evaluate · Save\n",
    "# ==============================================\n",
    "\n",
    "import json, numpy as np, tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "NUM_CLASSES = len(CLASS_ORDER)\n",
    "EMB_DIM = 128\n",
    "\n",
    "seq_in = layers.Input(shape=(CUTOFF_PLIES,), dtype=\"int32\", name=\"seq_in\")\n",
    "x = layers.Embedding(VOCAB_SIZE, EMB_DIM, mask_zero=True)(seq_in)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "x = layers.Dropout(0.20)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(128))(x)\n",
    "x = layers.Dropout(0.20)(x)\n",
    "seq_repr = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "num_in = layers.Input(shape=(len(ELO_FEATS),), dtype=\"float32\", name=\"num_in\")\n",
    "n = layers.LayerNormalization()(num_in)\n",
    "n = layers.Dense(32, activation=\"relu\")(n)\n",
    "\n",
    "h = layers.Concatenate()([seq_repr, n])\n",
    "h = layers.Dropout(0.15)(h)\n",
    "h = layers.Dense(128, activation=\"relu\")(h)\n",
    "out = layers.Dense(NUM_CLASSES, activation=\"softmax\", dtype=\"float32\")(h)\n",
    "\n",
    "model = models.Model([seq_in, num_in], out)\n",
    "model.summary()\n",
    "\n",
    "try:\n",
    "    opt = tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n",
    "except Exception:\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt_path = RESULTS_DIR / \"best_seq_model.keras\"\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(str(ckpt_path), monitor=\"val_loss\",\n",
    "                                       save_best_only=True, save_weights_only=False),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True, verbose=1),\n",
    "]\n",
    "\n",
    "EPOCHS = 40 if \"EPOCHS\" not in globals() else EPOCHS\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def eval_ds(m, ds, y, name):\n",
    "    p = m.predict(ds, verbose=0).argmax(1)\n",
    "    acc = accuracy_score(y, p)\n",
    "    f1m = f1_score(y, p, average=\"macro\")\n",
    "    rep = classification_report(y, p, target_names=CLASS_ORDER, output_dict=True, zero_division=0)\n",
    "    cm  = confusion_matrix(y, p).tolist()\n",
    "    print(f\"[{name}] acc={acc:.4f}  f1_macro={f1m:.4f}\")\n",
    "    return acc, f1m, rep, cm\n",
    "\n",
    "val_acc, val_f1, val_rep, val_cm = eval_ds(model, ds_val,  y_val,  \"Validation\")\n",
    "tst_acc, tst_f1, tst_rep, tst_cm = eval_ds(model, ds_test, y_test, \"Test\")\n",
    "\n",
    "report = {\n",
    "    \"config\": {\n",
    "        \"cutoff_full_moves\": int(CUTOFF_FULL_MOVES),\n",
    "        \"cutoff_plies\": int(CUTOFF_PLIES),\n",
    "        \"vocab_size\": int(VOCAB_SIZE),\n",
    "        \"embedding_dim\": int(EMB_DIM),\n",
    "        \"dropout\": {\"after_lstm\": 0.20, \"after_concat\": 0.15},\n",
    "        \"optimizer\": \"AdamW\" if isinstance(opt, tf.keras.optimizers.AdamW) else \"Adam\",\n",
    "        \"clipnorm\": 1.0,\n",
    "        \"epochs\": int(EPOCHS),\n",
    "        \"batch_size\": int(BATCH),\n",
    "        \"balanced_oversample_draws\": int(OVERSAMPLE_DRAWS),\n",
    "        \"elo_features\": ELO_FEATS\n",
    "    },\n",
    "    \"val\":  {\"acc\": float(val_acc),  \"f1_macro\": float(val_f1),  \"confusion_matrix\": val_cm},\n",
    "    \"test\": {\"acc\": float(tst_acc), \"f1_macro\": float(tst_f1), \"report\": tst_rep, \"confusion_matrix\": tst_cm},\n",
    "    \"artifacts\": {\"best_model\": str(ckpt_path), \"vocab\": str(RESULTS_DIR / \"vocab.json\")}\n",
    "}\n",
    "(RESULTS_DIR / \"seq_report.json\").write_text(json.dumps(report, indent=2))\n",
    "print(\"Saved:\", RESULTS_DIR / \"seq_report.json\")\n",
    "print(\"Best model:\", ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
